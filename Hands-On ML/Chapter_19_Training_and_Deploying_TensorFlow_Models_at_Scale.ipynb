{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Model Serving"
      ],
      "metadata": {
        "id": "pao9KF9nTHUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using TF Serving"
      ],
      "metadata": {
        "id": "qZ9HSjPp4lFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZhWMFpDSpzd"
      },
      "outputs": [],
      "source": [
        "# make and save model\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "model_name = \"my_mnist_model\"\n",
        "model_version = \"0001\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect SavedModel.\n",
        "# Output will be a 'tag', which is a classification of metagraph(calculation graph + function signature(e.g. type, input & output size)).\n",
        "!saved_model_cli show --dir '{model_path}'"
      ],
      "metadata": {
        "id": "JFBFtU1OTdPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the 'tag set' above.\n",
        "# Output will be a two signature definition, '__saved_model_init_op' and 'serving_default'.\n",
        "!saved_model_cli show --dir '{model_path}' --tag_set serve"
      ],
      "metadata": {
        "id": "HpjP2UPhUMa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look closely at the basic serving function 'serving_default'.\n",
        "!saved_model_cli show --dir '{model_path}' --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ],
      "metadata": {
        "id": "1NyTaR3_Uv9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install tensorflow serving\n",
        "url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
        "src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
        "!echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "!curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
        "!apt update -q && apt-get install -y tensorflow-model-server\n",
        "%pip install -q -U tensorflow-serving-api==2.11.1"
      ],
      "metadata": {
        "id": "qsI9kh7BU46Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
      ],
      "metadata": {
        "id": "5_Ddp_GVWQcH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement server\n",
        "%%bash --bg\n",
        "tensorflow_model_server \\\n",
        "    --port=8500 \\\n",
        "    --rest_api_port=8501 \\\n",
        "    --model_name=my_mnist_model \\\n",
        "    --model_base_path=\"${MODEL_DIR}\" >my_server.log 2>&1"
      ],
      "metadata": {
        "id": "U_mH9QsSW5zX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query to TF serving using REST API\n",
        "# make a request\n",
        "import json\n",
        "\n",
        "X_new = X_test[:3]\n",
        "request_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist()\n",
        "})"
      ],
      "metadata": {
        "id": "3a2SAFq5XjEA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# json is 100% text\n",
        "request_json"
      ],
      "metadata": {
        "id": "97gBW5IfX8D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deliver request data to TF serving using HTTP POST method\n",
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ],
      "metadata": {
        "id": "8NqJeWzAX9Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "import numpy as np\n",
        "y_proba = np.array(response['predictions'])\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "id": "J_L6tf0LYeDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query to TF serving using gRPC API\n",
        "# Make a request.\n",
        "# Make a PredictRequest protocol buffer and fill in fields.\n",
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_sepc.signature_name = 'serving_default'\n",
        "input_name = model.input_names[0]\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ],
      "metadata": {
        "id": "CkmPUz_uZp8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "# make a channel\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "\n",
        "# make a gRPC service for the channel\n",
        "predict_service = prediction_service_pb2_grpc.PredictServiceStub(channel)\n",
        "\n",
        "# send a request\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ],
      "metadata": {
        "id": "OVwmqswBaP3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change protocol buffer to tensor\n",
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)"
      ],
      "metadata": {
        "id": "-vJdzWZQa_9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a new version of model\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "iodYp7UUtAC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save a new version of model\n",
        "model_version = \"0002\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ],
      "metadata": {
        "id": "Wf2Mk4YztFxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}