{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Model Serving"
      ],
      "metadata": {
        "id": "pao9KF9nTHUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using TF Serving"
      ],
      "metadata": {
        "id": "qZ9HSjPp4lFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZhWMFpDSpzd"
      },
      "outputs": [],
      "source": [
        "# make and save model\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "model_name = \"my_mnist_model\"\n",
        "model_version = \"0001\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect SavedModel.\n",
        "# Output will be a 'tag', which is a classification of metagraph(calculation graph + function signature(e.g. type, input & output size)).\n",
        "!saved_model_cli show --dir '{model_path}'"
      ],
      "metadata": {
        "id": "JFBFtU1OTdPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the 'tag set' above.\n",
        "# Output will be a two signature definition, '__saved_model_init_op' and 'serving_default'.\n",
        "!saved_model_cli show --dir '{model_path}' --tag_set serve"
      ],
      "metadata": {
        "id": "HpjP2UPhUMa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look closely at the basic serving function 'serving_default'.\n",
        "!saved_model_cli show --dir '{model_path}' --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ],
      "metadata": {
        "id": "1NyTaR3_Uv9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install tensorflow serving\n",
        "url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
        "src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
        "!echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "!curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
        "!apt update -q && apt-get install -y tensorflow-model-server\n",
        "%pip install -q -U tensorflow-serving-api==2.11.1"
      ],
      "metadata": {
        "id": "qsI9kh7BU46Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
      ],
      "metadata": {
        "id": "5_Ddp_GVWQcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement server\n",
        "%%bash --bg\n",
        "tensorflow_model_server \\\n",
        "    --port=8500 \\\n",
        "    --rest_api_port=8501 \\\n",
        "    --model_name=my_mnist_model \\\n",
        "    --model_base_path=\"${MODEL_DIR}\" >my_server.log 2>&1"
      ],
      "metadata": {
        "id": "U_mH9QsSW5zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query to TF serving using REST API\n",
        "# make a request\n",
        "import json\n",
        "\n",
        "X_new = X_test[:3]\n",
        "request_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist()\n",
        "})"
      ],
      "metadata": {
        "id": "3a2SAFq5XjEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# json is 100% text\n",
        "request_json"
      ],
      "metadata": {
        "id": "97gBW5IfX8D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deliver request data to TF serving using HTTP POST method\n",
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ],
      "metadata": {
        "id": "8NqJeWzAX9Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "import numpy as np\n",
        "y_proba = np.array(response['predictions'])\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "id": "J_L6tf0LYeDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query to TF serving using gRPC API\n",
        "# Make a request.\n",
        "# Make a PredictRequest protocol buffer and fill in fields.\n",
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_sepc.signature_name = 'serving_default'\n",
        "input_name = model.input_names[0]\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ],
      "metadata": {
        "id": "CkmPUz_uZp8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "# make a channel\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "\n",
        "# make a gRPC service for the channel\n",
        "predict_service = prediction_service_pb2_grpc.PredictServiceStub(channel)\n",
        "\n",
        "# send a request\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ],
      "metadata": {
        "id": "OVwmqswBaP3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change protocol buffer to tensor\n",
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)"
      ],
      "metadata": {
        "id": "-vJdzWZQa_9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a new version of model\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "iodYp7UUtAC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save a new version of model\n",
        "model_version = \"0002\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ],
      "metadata": {
        "id": "Wf2Mk4YztFxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vertex AI"
      ],
      "metadata": {
        "id": "YlESlu5Zb5xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authorization\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "OFqGrQr2b-Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make GCS bucket to save SavedModel.\n",
        "from google.cloud import storage\n",
        "\n",
        "project_id = 'my_project'\n",
        "bucket_name = 'my_bucket'\n",
        "location = 'us-central1'\n",
        "\n",
        "storage_client = storage.Client(project=project_id)\n",
        "bucket = storage_client.create_bucket(bucket_name, location=location)"
      ],
      "metadata": {
        "id": "zptnZiEMcnsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to upload directory to a new bucket.\n",
        "def upload_directory(bucket, dirpath):\n",
        "    dirpath = Path(dirpath)\n",
        "    for filepath in dirpath.glob(\"**/*\"):\n",
        "        if filepath.is_file():\n",
        "            blob = bucket.blob(filepath.relative_to(dirpath.parent).as_posix())\n",
        "            blob.upload_from_filename(filepath)\n",
        "    upload_directory(bucket, \"my_mnist_model\")"
      ],
      "metadata": {
        "id": "d47Yc9fidR0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multithreading\n",
        "!gsutil -m cp -r my_mnist_model gs://{bucket_name}/"
      ],
      "metadata": {
        "id": "cLFlHDind1L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inform Vertex AI about the model.\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "server_image = 'gcr.io/cloud-aiplatform/prediction/tf2-gpu.2-8:latest'\n",
        "\n",
        "aiplatform.init(project=project_id, location=location)\n",
        "mnist_model = aiplatform.Model.upload(\n",
        "    display_name='mnist',\n",
        "    artifact_uri=f'gs://{bucket_name}/my_mnist_model/0001',\n",
        "    serving_container_image_uri=server_image,\n",
        ")"
      ],
      "metadata": {
        "id": "mpdBf1r9eOxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make endpoint\n",
        "endpoint = aiplatform.Endpoint.create(display_name='mnist-endpoint')\n",
        "\n",
        "endpoint.deploy(\n",
        "    mnist_model,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count-5,\n",
        "    machine_type='n1-standard-4',\n",
        "    accelerator_type='NVIDIA_TESLA_K80',\n",
        "    accelerator_count=1\n",
        ")"
      ],
      "metadata": {
        "id": "J99DY23ie3e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "response = endpoint.predict(instances=X_new.tolist())"
      ],
      "metadata": {
        "id": "Vdzfw2Tbfi-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.round(response.predictions, 2)"
      ],
      "metadata": {
        "id": "JqhggxgRfphm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove endpoint\n",
        "endpoint.undeploy_all()\n",
        "endpoint.delete()"
      ],
      "metadata": {
        "id": "rhZG2hMffv42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch prediction on Vertex AI"
      ],
      "metadata": {
        "id": "8bZOc1cDgJ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare batch and upload to GCS\n",
        "# make JSON Lines file\n",
        "batch_path = Path('my_mnist_batch')\n",
        "batch_path.mkdir(exist_ok=True)\n",
        "with open(batch_path / 'my_mnist_batch.jsonl', 'w') as jsonl_file:\n",
        "    for image in X_test[:100].tolist():\n",
        "        jsonl_file.write(json.dumps(image))\n",
        "        jsonl.file.write('\\n')\n",
        "\n",
        "upload_directory(bucket, batch_path)"
      ],
      "metadata": {
        "id": "htowIdRHgTFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set directory path\n",
        "batch_prediction_job = mnist_model.batch_predict(\n",
        "    job_display_name=\"my_batch_prediction_job\",\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    starting_replica_count=1,\n",
        "    max_replica_count=5,\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=1,\n",
        "    gcs_source=[f\"gs://{bucket_name}/{batch_path.name}/my_mnist_batch.jsonl\"],\n",
        "    gcs_destination_prefix=f\"gs://{bucket_name}/my_mnist_predictions/\",\n",
        "    sync=True\n",
        ")"
      ],
      "metadata": {
        "id": "qkPlxenDhFB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "y_probas = []\n",
        "for blob in batch_prediction_job.iter_outputs():\n",
        "    if 'prediction.results' in blob.name:\n",
        "        for line in blob.download_as_text().splitlines():\n",
        "            y_proba = json.loads(line)['prediction']\n",
        "            y_probas.append(y_proba)"
      ],
      "metadata": {
        "id": "6vvyCKkMhhdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "y_pred = np.argmax(y_probas, axis=1)\n",
        "accuracy = np.sum(y_pred == y_test[:100]) / 100"
      ],
      "metadata": {
        "id": "uY175b5biFn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete model, bucket and batch prediction job\n",
        "for prefix in ['my_mnist_model/', 'my_mnist_batch/', 'my_mnist_predictions/']:\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    for blob in blobs:\n",
        "        blob.delete()\n",
        "\n",
        "bucket.delete()\n",
        "batch_prediction_job.delete()"
      ],
      "metadata": {
        "id": "GUmuvbmbiZ2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribute models on mobile or embeded device"
      ],
      "metadata": {
        "id": "ib6yG9zqkVWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert SavedModel to FlatBuffers and save as .tflite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(model_path))\n",
        "tflite_model = converter.convert()\n",
        "with open(\"my_converted_savedmodel.tflite\", 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "-tZmcz1fkbj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after-training quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "metadata": {
        "id": "yj-SOliblv-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use GPU to Speed Up"
      ],
      "metadata": {
        "id": "J5VoYCYdow2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check tensorflow recognizes GPU\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "physical_gpus"
      ],
      "metadata": {
        "id": "i9FTIXjWo0CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set RAM limit of tensorflow\n",
        "for gpu in physical_gpus:\n",
        "    tf.config.set_logical_device_configuration(\n",
        "        gpu,\n",
        "        [tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
        "    )"
      ],
      "metadata": {
        "id": "fRGXPcF4pk8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make tensorflow occupy GPU only if necessary\n",
        "for gpu in physical_gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "AoZYg1Jtp7hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide GPU into 2+ logical devices\n",
        "tf.config.set_logical_device_configuration(\n",
        "    physical_gpus[0],\n",
        "    [tf.config.LogicalDeviceConfiguration(memory_limit=2048),\n",
        "     tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
        ")"
      ],
      "metadata": {
        "id": "uGp7o4FaqL4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check logical devices\n",
        "logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "logical_gpus"
      ],
      "metadata": {
        "id": "u2hhspgQqdo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Allocating Computation and Variable to Device"
      ],
      "metadata": {
        "id": "OsJah8beq8SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.Variable([1., 2., 3.])\n",
        "a.device    # check device\n",
        "b = tf.Variable([1, 2, 3])\n",
        "b.device"
      ],
      "metadata": {
        "id": "HfQGVA-jrGXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change device\n",
        "with tf.device(\"/cpu:0\"):\n",
        "    c = tf.Variable([1., 2., 3.])\n",
        "c.device"
      ],
      "metadata": {
        "id": "HAkb-NZYreI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model on Multiple Devices"
      ],
      "metadata": {
        "id": "IHpT1cDY-Xql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large Scale Training Using Distributed Strategy API\n",
        "\n"
      ],
      "metadata": {
        "id": "MYABMWe77LeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make strategy object\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# wrap with distirbute context\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([...])\n",
        "    model.compile([...])\n",
        "\n",
        "batch_size = 100        # should be divided by the number of mirrored models\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "UaKDgyV_7fMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap with context when loading model\n",
        "with strategy.scope():\n",
        "    model = tf.keras.models.load_model(\"my_mirrored_model\")"
      ],
      "metadata": {
        "id": "vZDSKWl18Nng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deliver the list of devices if you want to use part of GPUs\n",
        "strategy = tf.distribute.MirroredStrategy(devices=['/gpu:0', '/gpu:1'])"
      ],
      "metadata": {
        "id": "MxB3tjhm8qDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use centralized parameter\n",
        "strategy = tf.distribute.experimental.CentralStorageStrategy()"
      ],
      "metadata": {
        "id": "OkzgAwaT9O0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF Cluster"
      ],
      "metadata": {
        "id": "8-Sm5AU1-Bpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster specification\n",
        "cluster_spec = {\n",
        "    \"worker\": [\n",
        "        \"machine-a.example.com:2222\",     # /job:worker/task:0\n",
        "        \"machine-b.example.com:2222\"      # /job:worker/task:1\n",
        "    ],\n",
        "    \"ps\": [\"machine-a.example.com:2221\"]  # /job:ps/task:0\n",
        "}"
      ],
      "metadata": {
        "id": "aMj9UiAF-BEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deliver cluster specification and set task type when starting task\n",
        "os.environ['TF_CONFIG'] = json.dumps({\n",
        "    'cluster': cluster_spec,\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "})"
      ],
      "metadata": {
        "id": "rlwqUqDS-4NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "print(f\"Starting task {resolver.task_type} #{resolver.task_id}\")\n",
        "\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Reshape([28, 28, 1], input_shape=[28, 28],\n",
        "                                dtype=tf.uint8),\n",
        "        tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                               padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=10, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10)\n",
        "\n",
        "if resolver.task_id == 0:  # chief stores model in the right position\n",
        "    model.save(\"my_mnist_multiworker_model\", save_format=\"tf\")\n",
        "else:\n",
        "    tmpdir = tempfile.mkdtemp()  # other workers stored in temporary directory\n",
        "    model.save(tmpdir, save_format=\"tf\")\n",
        "    tf.io.gfile.rmtree(tmpdir)  # remove directory"
      ],
      "metadata": {
        "id": "DuYM_SuO_Zf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assert NCCL to network communication\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy(\n",
        "    communication_options = tf.distribute.experimental.CommunicationOptions(\n",
        "        implementation = tf.distribute.experimental.CollectiveCommunication.NCCL\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "G-vWcCQ3_kf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TPUStrategy when TPU is available\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "zW8jMiev_8qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large Scale Training in Vertex AI\n"
      ],
      "metadata": {
        "id": "4pZXee30Ts2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "\n",
        "if resolver.task_type == \"chief\":\n",
        "    model_dir = os.getenv(\"AIP_MODEL_DIR\")  # provided by Vertex AI\n",
        "    tensorboard_log_dir = os.getenv(\"AIP_TENSORBOARD_LOG_DIR\")\n",
        "    checkpoint_dir = os.getenv(\"AIP_CHECKPOINT_DIR\")\n",
        "else:\n",
        "    tmp_dir = Path(tempfile.mkdtemp())\n",
        "    model_dir = tmp_dir / \"model\"\n",
        "    tensorboard_log_dir = tmp_dir / \"logs\"\n",
        "    checkpoint_dir = tmp_dir / \"ckpt\"\n",
        "\n",
        "callbacks = [tf.keras.callbacks.TensorBoard(tensorboard_log_dir),\n",
        "             tf.keras.callbacks.ModelCheckpoint(checkpoint_dir)]\n",
        "\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Reshape([28, 28, 1], input_shape=[28, 28],\n",
        "                                dtype=tf.uint8),\n",
        "        tf.keras.layers.Lambda(lambda X: X / 255),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                               padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=10, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model.save(model_dir, save_format=\"tf\")"
      ],
      "metadata": {
        "id": "2ktTLoA3Uj2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_training_job = aiplatform.CustomTrainingJob(\n",
        "    display_name=\"my_custom_training_job\",\n",
        "    script_path=\"my_vertex_ai_training_task.py\",\n",
        "    container_uri=\"gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest\",\n",
        "    model_serving_container_image_uri=server_image,\n",
        "    requirements=[\"gcsfs==2022.3.0\"],\n",
        "    staging_bucket=f\"gs://{bucket_name}/staging\"\n",
        ")"
      ],
      "metadata": {
        "id": "bo6NwOPDVRrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run on two workers\n",
        "mnist_model2 = custom_training_job.run(\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    replica_count=2,\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=2,\n",
        ")"
      ],
      "metadata": {
        "id": "TOJqgbgiVs34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning in Vertex AI\n"
      ],
      "metadata": {
        "id": "baZ7ZSXYWuph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use argparse library to get hyperparameter value as an argument.\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--n_hidden', type=int, default=2)\n",
        "parser.add_argument('--n_neurons', type=int, default=256)\n",
        "parser.add_argument('--learning_rate', type=float, default=1e-2)\n",
        "parser.add_argument('--optimizer', default='adam')\n",
        "args = parser.parse_args()"
      ],
      "metadata": {
        "id": "isce5_2XWyJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use mirrored strategy to perform trials in multi GPU machine.\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_model(args):\n",
        "    with tf.distribute.MirroredStrategy().scope():\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8))\n",
        "        for _ in range(args.n_hidden):\n",
        "            model.add(tf.keras.layers.Dense(args.n_neurons, activation=\"relu\"))\n",
        "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "        opt = tf.keras.optimizers.get(args.optimizer)\n",
        "        opt.learning_rate = args.learning_rate\n",
        "        model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,\n",
        "                      metrixs=['accuracy'])\n",
        "        return model\n",
        "\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "import os\n",
        "model_dir = os.getenv(\"AIP_MODEL_DIR\")\n",
        "tensorboard_log_dir = os.getenv(\"AIP_TENSORBOARD_LOG_DIR\")\n",
        "checkpoint_dir = os.getenv(\"AIP_CHECKPOINT_DIR\")\n",
        "trial_id = os.getenv(\"CLOUD_ML_TRIAL_ID\")\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(tensorboard_log_dir)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n",
        "callbacks = [tensorboard_cb, early_stopping_cb]\n",
        "\n",
        "model = build_model(args)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
        "                    epochs=10, callbacks=callbacks)\n",
        "model.save(model_dir, save_format=\"tf\")"
      ],
      "metadata": {
        "id": "14-5eiqrXcbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use hypertune library to report performance of model to Vertex AI service and select the next combinations\n",
        "import hypertune\n",
        "\n",
        "hypertune = hypertune.HyperTune()\n",
        "hypertune.report_hyperparameter_tuning_metric(\n",
        "    hyperparameter_metric_tag=\"accuracy\",\n",
        "    metric_value=max(history.history[\"val_accuracy\"]),\n",
        "    global_step=model.optimizer.iterations.numpy(),\n",
        ")"
      ],
      "metadata": {
        "id": "b7J0yOSWY5vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define type of machine.\n",
        "trial_job = aiplatform.CustomJob.from_local_script(\n",
        "    display_name=\"my_search_trial_job\",\n",
        "    script_path=\"my_vertex_ai_trial.py\",\n",
        "    container_uri=\"gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest\",\n",
        "    staging_bucket=f'gs://{bucket_name}/staging',\n",
        "    accelerator_type='NVIDIA_TESLA_K80',\n",
        "    accelerator_count=2,\n",
        ")"
      ],
      "metadata": {
        "id": "HpgIK0ELY_AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune hyperparemeters.\n",
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "hp_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name='my_hp_search_job',\n",
        "    custom_job=trial_job,\n",
        "    metric_spec={'accuracy': 'maximize'},\n",
        "    parameter_spec={\n",
        "        'learning_rate': hpt.DoubleParameterSpec(min=1e-4, max=10, scale='log'),\n",
        "        'n_neurons':hpt.IntegerParameterSpec(min=1, max=300, scale='linear'),\n",
        "        'n_hidden': hpt.IntegerParameterSpec(min=1, max=10, scale='linear'),\n",
        "        'optimizer': hpt.CategoricalParameterSpec(['adam', 'sgd']),\n",
        "    },\n",
        "    max_trial_count=100,\n",
        "    parallel_trial_count=20,\n",
        ")\n",
        "hp_job.run()"
      ],
      "metadata": {
        "id": "eLZCMiwSZ6be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a result.\n",
        "def get_final_metric(trial, metric_id):\n",
        "    for metric in trial.final_measurement.metrics:\n",
        "        if metric.metric_id == metric_id:\n",
        "            return metric.value\n",
        "\n",
        "trials = hp_job.trials\n",
        "trial_accuracies = [get_final_metric(trial, 'accuracy') for trial in trials]\n",
        "best_trial = trials[np.argmax(trial_accuracies)]"
      ],
      "metadata": {
        "id": "ZIDoDohybNUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(trial_accuracies)"
      ],
      "metadata": {
        "id": "5DctlYBmb2fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial.id"
      ],
      "metadata": {
        "id": "URxF1HAmb4cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial.parameters"
      ],
      "metadata": {
        "id": "SEU6OrNGb6Jo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}